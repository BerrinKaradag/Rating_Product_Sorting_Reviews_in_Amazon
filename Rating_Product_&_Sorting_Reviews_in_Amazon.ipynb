{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 9420296,
          "sourceType": "datasetVersion",
          "datasetId": 5721658
        }
      ],
      "dockerImageVersionId": 30775,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Rating Product & Sorting Reviews in Amazon",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BerrinKaradag/Rating_Product__Sorting_Reviews_in_Amazon/blob/main/Rating_Product_%26_Sorting_Reviews_in_Amazon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'amazon:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5721658%2F9420296%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240929%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240929T145141Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Db81782444f19ea80dadd93e450bc46801f7cb1da3ba9e3bfe041b0d0fdd30f6ff6b19caefc56c69c0fc716292ad43e6b9a062e33b4261297274eb6f14d76124d7ca11a5ba5e7fa76a15cd703837229d4dbbf473885bbf0ffaff078fdd770774753b92ae05520713b49995397712c4eac95e4d370e242fe95b7aad7524b47e7324041b4b37a6c59f48569b254c76299bfc0b5f7c7825fcffbe1c8c6a61d75736aab9e34cdb03adcda5f8e389aed3ce8ba1802c9b0c66f60d860c7aec7e0405b5f32197b7699d22158dedcd17e4289b1f26a756c8d70cb223d35acaf059b31145d1804cdf90fbc2f160d19c2bb61f7869fccac846f9f4419c8c4bb83b107d5d024'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "TuOwAWFaRBzX",
        "outputId": "135ccef1-09b8-46f6-a697-456defb16809",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading amazon, 721801 bytes compressed\n",
            "[==================================================] 721801 bytes downloaded\n",
            "Downloaded and uncompressed: amazon\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Case:** One of the most important problems in e-commerce is the correct calculation of the scores given to the products after the sale. The solution to this problem means providing more customer satisfaction for the e-commerce site, highlighting the product for the sellers and a smooth shopping experience for the buyers. Another problem is the correct ordering of the comments given to the products. Since the prominence of misleading comments will directly affect the sales of the product, it will cause both financial loss and loss of customers. In the solution of these 2 basic problems, the e-commerce site and the sellers will increase their sales while the customers will complete the purchasing journey smoothly.\n",
        "\n",
        "This dataset, which contains Amazon product data, includes product categories and various metadata. The product with the most comments in the electronics category has user ratings and comments.\n",
        "\n",
        "**Task 1:** Calculate the Average Rating based on current reviews and compare with the existing average rating.\n",
        "\n",
        "**Task 2:** Determine 20 reviews to be displayed on the product detail page for the product."
      ],
      "metadata": {
        "id": "Hplarm12RBzb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Variables**\n",
        "\n",
        "reviewerID - ID of the reviewer\n",
        "\n",
        "asin - ID of the product\n",
        "\n",
        "reviewerName - name of the reviewer\n",
        "\n",
        "helpful - helpfulness rating of the review\n",
        "\n",
        "reviewText - text of the review\n",
        "\n",
        "overall - rating of the product\n",
        "\n",
        "summary - summary of the review\n",
        "\n",
        "unixReviewTime - time of the review (unix time)\n",
        "\n",
        "reviewTime - time of the review (raw)\n",
        "\n",
        "day_diff - Number of days since the review\n",
        "\n",
        "helpful_yes - Number of times the review was found helpful\n",
        "\n",
        "total_vote - Number of votes given to the review"
      ],
      "metadata": {
        "id": "BH7N79VlRBzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "#wilsonlower bound i√ßin:\n",
        "import math\n",
        "import scipy.stats as st"
      ],
      "metadata": {
        "id": "_ihDbRIFRBzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/kaggle/input/amazon/amazon_review.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-29T13:50:53.209193Z",
          "iopub.execute_input": "2024-09-29T13:50:53.209638Z",
          "iopub.status.idle": "2024-09-29T13:50:53.281377Z",
          "shell.execute_reply.started": "2024-09-29T13:50:53.209599Z",
          "shell.execute_reply": "2024-09-29T13:50:53.280124Z"
        },
        "trusted": true,
        "id": "JACu554FRBzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 1:Calculate the Average Rating based on current reviews and compare with the existing average rating**.\n",
        "\n",
        "In the shared dataset, users have given points and made comments on a product. In this task, our aim is to evaluate the given points by weighting them according to date. The first average point and the weighted point according to date to be obtained must be compared.\n",
        "\n",
        "**Step 1:** Calculate the average point of the product."
      ],
      "metadata": {
        "id": "rPepcNHDRBzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"overall\"].mean()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-29T13:51:06.694213Z",
          "iopub.execute_input": "2024-09-29T13:51:06.694649Z",
          "iopub.status.idle": "2024-09-29T13:51:06.704918Z",
          "shell.execute_reply.started": "2024-09-29T13:51:06.694611Z",
          "shell.execute_reply": "2024-09-29T13:51:06.703564Z"
        },
        "trusted": true,
        "id": "jNyLrKThRBzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2:** Calculate the weighted average score by date."
      ],
      "metadata": {
        "id": "a74uJs-_RBze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def average_score (data, w1=50, w2=25, w3=15, w4=10):\n",
        "    return data.loc[data[\"day_diff\"]<=data[\"day_diff\"].quantile(0.25), \"overall\"].mean() *w1/100 +\\\n",
        "           data.loc[(data[\"day_diff\"]>data[\"day_diff\"].quantile(0.25)) & (data[\"day_diff\"]<=data[\"day_diff\"].quantile(0.50)), \"overall\"].mean() *w2/100 +\\\n",
        "           data.loc[(data[\"day_diff\"]>data[\"day_diff\"].quantile(0.50)) & (data[\"day_diff\"]<= data[\"day_diff\"].quantile(0.75)), \"overall\"].mean() * w3/100 +\\\n",
        "           data.loc[data[\"day_diff\"]> data[\"day_diff\"].quantile(0.75), \"overall\"].mean()*w4/100\n",
        "\n",
        "average_score(df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-29T13:51:21.793681Z",
          "iopub.execute_input": "2024-09-29T13:51:21.794189Z",
          "iopub.status.idle": "2024-09-29T13:51:21.825649Z",
          "shell.execute_reply.started": "2024-09-29T13:51:21.794137Z",
          "shell.execute_reply": "2024-09-29T13:51:21.823753Z"
        },
        "trusted": true,
        "id": "0dtiWtJERBze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3:** Compare and interpret the average of each time period in the weighted score."
      ],
      "metadata": {
        "id": "RTHssjb4RBze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def period (data, w1=50, w2=25, w3=15, w4=10):\n",
        "    q1= data.loc[data[\"day_diff\"]<=data[\"day_diff\"].quantile(0.25), \"overall\"].mean() *w1/100\n",
        "    q2= data.loc[(data[\"day_diff\"]>data[\"day_diff\"].quantile(0.25)) & (data[\"day_diff\"]<=data[\"day_diff\"].quantile(0.50)), \"overall\"].mean() *w2/100\n",
        "    q3= data.loc[(data[\"day_diff\"]>data[\"day_diff\"].quantile(0.50)) & (data[\"day_diff\"]<= data[\"day_diff\"].quantile(0.75)), \"overall\"].mean() * w3/100\n",
        "    q4= data.loc[data[\"day_diff\"]> data[\"day_diff\"].quantile(0.75), \"overall\"].mean()*w4/100\n",
        "    weighted_avg = q1* w1 / 100 + q2 * w2 / 100 + q3 * w3 / 100 + q4 * w4 / 100\n",
        "\n",
        "    return {\n",
        "        \"Q1 (Newest %25)\": q1,\n",
        "        \"Q2\": q2,\n",
        "        \"Q3\": q3,\n",
        "        \"Q4 (Oldest %25)\": q4,\n",
        "        \"Weighted Average\": weighted_avg\n",
        "    }\n",
        "\n",
        "period(df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-29T13:55:14.298291Z",
          "iopub.execute_input": "2024-09-29T13:55:14.298904Z",
          "iopub.status.idle": "2024-09-29T13:55:14.327148Z",
          "shell.execute_reply.started": "2024-09-29T13:55:14.298856Z",
          "shell.execute_reply": "2024-09-29T13:55:14.325653Z"
        },
        "trusted": true,
        "id": "jjrwgSlBRBzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2: Determine 20 reviews to be displayed on the product detail page for the product.**\n",
        "\n",
        "**Step 1:** Generate the helpful_no variable.\n",
        "\n",
        "‚Ä¢ total_vote is the total number of up-downs given to a comment.\n",
        "\n",
        "‚Ä¢ up means helpful.\n",
        "\n",
        "There is no helpful_no variable in the dataset, it needs to be generated from the existing variables. Find the number of votes that are not found helpful (helpful_no) by subtracting the number of helpful votes (helpful_yes) from the total number of votes (total_vote)"
      ],
      "metadata": {
        "id": "tPW7VV4sRBzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"helpful_no\"]=df[\"total_vote\"]-df[\"helpful_yes\"]\n",
        "df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-29T14:00:06.427483Z",
          "iopub.execute_input": "2024-09-29T14:00:06.427963Z",
          "iopub.status.idle": "2024-09-29T14:00:06.454994Z",
          "shell.execute_reply.started": "2024-09-29T14:00:06.42792Z",
          "shell.execute_reply": "2024-09-29T14:00:06.453293Z"
        },
        "trusted": true,
        "id": "v7GSwODPRBzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2:** Calculate score_pos_neg_diff, score_average_rating and wilson_lower_bound scores and add them to the data.\n",
        "\n",
        "score_pos_neg_diff: Useful votes - Unhelpful votes\n",
        "\n",
        "score_average_rating: Useful votes / Total votes\n",
        "\n",
        "wilson_lower_bound: Statistical method used to assess the reliability of ratings, especially binary (e.g., \"like/dislike\", \"up/down\") ratings. This method allows a review (or product) to be reliably ranked based on the number of positive ratings it has received. The goal is to prevent reviews with a small number of high ratings from being ranked higher than reviews with a large number of average ratings. Thus, reviews with only a few positive ratings are kept at the bottom when making a reliable ranking.\n",
        "\n",
        "‚Ä¢ Create scores according to score_pos_neg_diff. Then; save it in df with the name score_pos_neg_diff.\n",
        "\n",
        "‚Ä¢ Create scores according to score_average_rating. Then; save it in df with the name score_average_rating.\n",
        "\n",
        "‚Ä¢ Create scores according to wilson_lower_bound. Then; save it in df with the name wilson_lower_bound."
      ],
      "metadata": {
        "id": "LKkj6WyjRBzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"score_pos_nef_diff\"]=df[\"helpful_yes\"]-df[\"helpful_no\"]\n",
        "df[\"score_average_rating\"]=df[\"helpful_yes\"]/df[\"total_vote\"]\n",
        "\n",
        "\n",
        "def wilson_lower_bound(up, down, confidence=0.95):\n",
        "    n = up + down\n",
        "    if n == 0:\n",
        "        return 0\n",
        "    z = st.norm.ppf(1 - (1 - confidence) / 2)\n",
        "    phat = 1.0 * up / n\n",
        "    return (phat + z * z / (2 * n) - z * math.sqrt((phat * (1 - phat) + z * z / (4 * n)) / n)) / (1 + z * z / n)\n",
        "\n",
        "df[\"wilson_lower_bound\"]=df.apply(lambda x: wilson_lower_bound(x[\"helpful_yes\"], x[\"helpful_no\"]), axis=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-29T14:35:09.588988Z",
          "iopub.execute_input": "2024-09-29T14:35:09.591441Z",
          "iopub.status.idle": "2024-09-29T14:35:09.838967Z",
          "shell.execute_reply.started": "2024-09-29T14:35:09.59134Z",
          "shell.execute_reply": "2024-09-29T14:35:09.837694Z"
        },
        "trusted": true,
        "id": "FEFNsQR_RBzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3:** Identify and rank the first 20 comments by wilson_lower_bound."
      ],
      "metadata": {
        "id": "HAYFa3AgRBzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.sort_values(\"wilson_lower_bound\", ascending=False).head(20)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-29T14:35:15.590367Z",
          "iopub.execute_input": "2024-09-29T14:35:15.590809Z",
          "iopub.status.idle": "2024-09-29T14:35:15.635428Z",
          "shell.execute_reply.started": "2024-09-29T14:35:15.590768Z",
          "shell.execute_reply": "2024-09-29T14:35:15.634154Z"
        },
        "trusted": true,
        "id": "t0cCImz9RBzg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}